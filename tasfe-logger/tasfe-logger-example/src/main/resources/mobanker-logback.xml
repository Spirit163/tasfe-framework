<?xml version="1.0" encoding="UTF-8"?>
<configuration debug="false">
    <substitutionProperty name="log.base" value="./logs"/>
    <!--LOG_HOME为日志保存的文件夹（必填、非空）-->
    <property name="LOG_HOME" value="${user.dir}/logs/tasfe"/>
    <property name="tasfe_LOG" value="root"/>
    <property name="ACTIVEMQ_LOG" value="activeMQ"/>
    <property name="RABBITMQ_LOG" value="rabbitMQ"/>
    <!--SUFFIX配置为日志文件的后缀名(必填、不为空、能够区分其他日志)-->
    <property name="SUFFIX" value=".Omitted.log"/>

    <!-- 产线名称,按照公司统一规范 -->
    <!-- 手机贷sjd;u族uzone;应花yhfq;星辰star;卡宜贷kyd;风控rcd;财务cwd;公共pub;架构arch;大数据bigdata;自动化测试autotest;框架fx;爬虫crawler;前隆卡qlcard-->
    <property name="productLine" value="fx"/>
    <!-- 应用名称,各业务根据需求自定义,统一小写 -->
    <property name="appName" value="ee2.1"/>

    <!-- 控制台输出 -->
    <appender name="STDOUT" class="ch.qos.logback.core.ConsoleAppender">
        <encoding>UTF-8</encoding>
        <encoder class="ch.qos.logback.classic.encoder.PatternLayoutEncoder">
            <!--格式化输出：%d表示日期，%thread表示线程名，%-5level：级别从左显示5个字符宽度%msg：日志消息，%n是换行符 -->
            <pattern>%d{yyyy-MM-dd HH:mm:ss.SSS} [%thread] %-5level %logger{50} - %msg%n</pattern>
        </encoder>
    </appender>

    <!-- 按照每天生成日志文件 -->
    <appender name="OMITTEDFILE" class="ch.qos.logback.core.rolling.RollingFileAppender">
        <encoding>UTF-8</encoding>
        <rollingPolicy class="ch.qos.logback.core.rolling.SizeAndTimeBasedRollingPolicy">
            <!--日志文件输出的文件名 -->
            <FileNamePattern>${LOG_HOME}/${tasfe_LOG}.%d{yyyy-MM-dd}.%i${SUFFIX}</FileNamePattern>
            <!--日志文件保留天数 -->
            <MaxHistory>7</MaxHistory>
            <maxFileSize>100MB</maxFileSize>
            <cleanHistoryOnStart>true</cleanHistoryOnStart>
        </rollingPolicy>
        <encoder class="com.tasfe.framework.logagent.logback.pattern.TasfeFilePatternLayout">
            <layout class="com.tasfe.framework.logagent.logback.pattern.TasfePatternLayout">
                <!--格式化输出：%d表示日期，%thread表示线程名，%-5level：级别从左显示5个字符宽度%msg：日志消息，%n是换行符 -->
                <pattern>%id ${productLine} ${appName} %ip %timeStamp %thread %level %msg%n</pattern>
            </layout>
        </encoder>
    </appender>

    <!-- log输出kafka -->
    <appender name="KAFKA" class="com.tasfe.framework.logagent.logback.KafkaAppender">
        <encoder class="com.tasfe.framework.logagent.logback.encoding.LayoutKafkaMessageEncoder">
            <layout class="com.tasfe.framework.logagent.logback.pattern.TasfePatternLayout">
                <pattern>%id ${productLine} ${appName} %ip %timeStamp %thread %level %msg</pattern>
            </layout>
        </encoder>
        <topic>tasfe.log4j</topic>
        <keyingStrategy class="com.tasfe.framework.logagent.logback.keying.RoundRobinKeyingStrategy"/>
        <deliveryStrategy class="com.tasfe.framework.logagent.logback.delivery.AsynchronousDeliveryStrategy"/>
        <appender-ref ref="OMITTEDFILE"/>
    </appender>

    <!-- spring -->
    <logger name="org.springframework" additivity="true" level="INFO"/>
    <!--myibatis log configure -->
    <logger name="com.apache.ibatis" level="INFO"/>
    <logger name="java.sql.Connection" level="INFO"/>
    <logger name="java.sql.Statement" level="INFO"/>
    <logger name="java.sql.PreparedStatement" level="INFO"/>
    <logger name="org.apache.zookeeper" level="OFF"/>
    <logger name="io.netty.handler.logging.LoggingHandler" level="OFF"/>
    <logger name="org.apache.kafka.clients" level="OFF"/>

    <!-- 日志输出级别 ：测试环境为DEBUG级别，生产环境置为INFO级别-->
    <root level="INFO">
        <appender-ref ref="STDOUT"/>
        <!--<appender-ref ref="OMITTEDFILE"/>-->
        <appender-ref ref="KAFKA"/>
    </root>
</configuration>